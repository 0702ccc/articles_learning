## **Parslo: A Gradient Descent-based Approach for Near-optimal Partial SLO Allotment in Microservices**

#### Abstract

这篇论文提出了Parslo算法，用于优化微服务图中的部分服务级别目标（SLO）的分配，以确保端到端延迟目标的实现。Parslo通过将端到端SLO预算拆分为小的增量“SLO单位”，并将这些单位逐步分配给最能节省成本的微服务，来实现接近最优的解决方案。这种方法能够处理复杂的微服务图结构，包括动态分支和微服务之间的依赖关系，从而在实际应用中将服务部署成本降低了超过6倍。Parslo的梯度下降优化策略使得它在处理实际应用中的复杂性和不确定性时表现出色。这种逐步优化的方法强调了系统整体协调与资源分配的重要性，显示了在现代云服务设计与优化中，综合考虑整个系统的资源使用是至关重要的



#### Introduction

现代云服务越来越倾向于采用微服务架构，即将复杂的应用程序拆分成数十到数百个独立、松散耦合的组件，以提高可编程性、可靠性和可扩展性。在这种架构中，服务级别目标（SLO）定义了端到端延迟的目标，以确保用户满意度。然而，如何在端到端SLO未达标或资源使用不足时优化单个微服务的扩展，以及如何在最小总成本下为每个微服务确定合适的规模，仍然是一个挑战。论文提出了Parslo，一种基于梯度下降的算法，用于在微服务图中分配部分SLO，以满足端到端延迟目标。Parslo通过将端到端SLO预算拆分为小的增量“SLO单位”，并逐步将这些单位分配给最佳的微服务，从而实现接近最优的解决方案。该方法能够处理复杂的微服务图结构，包括动态分支、并行扩展和微服务依赖关系，使服务部署成本在实际应用中减少了超过6倍。Parslo的主要贡献在于它能够在不改变系统运行时行为的前提下，提供近似最优的部分SLO分配，从而显著降低端到端的部署成本。这表明，尽管自动扩展和监控系统已经能够动态调整资源，合理的SLO分配和优化仍然是提高系统整体效率的关键。Parslo不仅提供了一种实用的优化方法，还展示了如何通过合理的算法设计，在复杂的微服务环境中有效地解决实际问题并取得显著的成本效益。



#### Background and Motivation

**2.1 延迟SLO和自动扩展器**

服务级别目标（SLO）用于定义云应用的关键属性，如可用性和延迟。云服务的弹性特性允许根据请求的到达率迅速调整实例的数量，以确保满足端到端的延迟SLO。延迟SLO通常基于端到端延迟分布的尾部（例如99百分位）来定义，以保证用户体验。然而，实际操作中，当尾部延迟超过SLO约束时，水平自动扩展器会增加实例数来降低排队延迟，反之则会减少实例数来节约成本。为了提高扩展效率，服务通常会在离线状态下进行剖析，以得出负载-延迟剖面（LLP），帮助确定实例的最大利用率，从而实现更加精确的水平自动扩展。此外，垂直自动扩展器则通过调整单个实例的资源量来优化资源使用，虽然这种方法较少见，但在共享资源的场景下（如固定预算的共置服务）尤其重要。

**2.2 微服务的延迟SLO**

现代服务通常以有向无环图（DAG）的形式实现，其中每个微服务的延迟SLO是基于整个服务的端到端响应时间来定义的。对于微服务架构，如何在端到端延迟SLO违反或资源使用不足时调整每个微服务的规模是一个挑战。现有的两种主要方法包括：一种是对每个微服务分配部分SLO，这种方法虽然简单，但通常是经验性的，可能导致总体成本的上升；另一种是使用机器学习驱动的端到端自动扩展框架，这些框架可以快速响应微服务图的拓扑变化，但实现复杂且缺乏最优性保证。

**2.3 最优的部分SLO分配**

以往的部分SLO分配方法常常采用经验性分配，可能导致成本的非最优化。例如，一些研究提出根据微服务的平均服务时间将端到端SLO按比例分配，这种方法在微服务的响应时间独立且SLO基于平均延迟时有效。然而，在微服务链中，如果各个微服务的LLP图形不一致或实例成本不同，这种方法可能会导致高达24%的成本降低。此外，这种方法仅适用于微服务链，难以推广到实际应用中的复杂DAG。因此，论文提出了一种系统化的方法，旨在给定端到端延迟SLO预算的情况下，优化每个微服务的部分SLO分配，从而最小化总体成本，并适用于一般的微服务DAG。

**个人理解：**

延迟SLO是保证用户体验的关键，而自动扩展器的精确调节是实现这一目标的核心。对于微服务架构，现有的部分SLO分配方法往往存在非最优的问题，因为它们未能充分考虑微服务间的复杂依赖关系和不同实例的资源配置。虽然机器学习驱动的自动扩展框架能够动态调整，但其复杂性和高昂的计算成本使得这种方法在实际应用中不够实际。因此，寻找一种既能系统化又能在实际应用中有效的SLO分配方法，是提高系统性能和降低成本的关键。



#### **SLO ALLOTMENT**

Parslo 是一个基于梯度下降 (GD) 的迭代优化框架，用于将部分服务级别目标 (SLO) 分配给有向无环图 (DAG) 中的微服务。目标是最小化部署成本，同时满足整体端到端延迟 SLO。

**算法描述:**

- **初始化: **将整体 SLO 拆分为较小的单位，所有微服务初始时分配一个 SLO 单位，建立基线成本。
- **迭代分配: **选择分配额外 SLO 单位的微服务，以实现最大成本节省。成本节省依据实例利用率变化计算。继续分配直到使用完全部 SLO 预算。
- **计算效率:** 算法复杂度线性与增量 SLO 单位和微服务数量相关。使用优先队列将复杂度降低为对数级别。
- **处理复杂 DAG:** 动态分支、RPC 和依赖关系、并行扩展

**局限性和考虑:**

- 在特定条件下（如 LLP 一致性）保证接近最优解。
- LLP 的非凸成本空间可能导致次优解。
- 设计用于无状态微服务，有状态组件或外部服务需单独处理。

**复杂性和性能:**

- 对于少于 1000 个节点和小于 10 个分支度的 DAG 表现良好。
- 可通过并行化和算法改进进一步优化。

Parslo 通过梯度下降方法迭代优化，将部分 SLO 有效分配给 DAG 中的微服务。它能够处理复杂的 DAG 结构和微服务的动态特性，如分支、RPC 依赖和并行处理。算法在处理大规模 DAG 时表现出色，但仍需关注局限性，如非凸成本空间和有状态服务的处理。整体上，Parslo 适合于需要高效 SLO 分配的场景，通过优化计算性能和处理复杂情况，能显著提升微服务系统的部署效率。



#### Evaluation

为了评估Parslo框架，作者选择了几种不同类型的微服务DAG进行模拟实验，包括合成DAG和来自DeathStarBench的两个真实应用程序（社交网络和媒体服务）。实验在Kubernetes环境中进行部署，合成DAG使用BigHouse框架进行随机排队仿真，基于FLANN、McRouter和Word Stemming (WS) 这三种常见的微服务模型进行服务时间分布测量。实际应用程序的实验中，每个实例在Kubernetes中作为一个pod运行，资源限制与资源请求相等，并使用Kubernetes的水平Pod自动扩展器（HPA）以CPU利用率为目标进行扩展。

在实验过程中，作者首先比较了Parslo与现有的两种基准方法，即Kubernetes HPA的固定利用率范围策略（目标为10%-30%和30%-70%）以及GrandSLAm的SLO分配方法。实验结果显示，Parslo在多种情况下（如较紧的SLO目标、尾部延迟SLO定义、实例类型不同）均优于GrandSLAm，特别是在合成的DAG和真实应用场景中，通过离线校准和混合校准方法，Parslo显著降低了部署成本，同时在某些情况下，较紧的SLO目标下性能改善尤为显著。

在对实际应用的测试中，Parslo与Kubernetes HPA和GrandSLAm相比，展现出更优的成本控制能力。在目标为3倍零负载延迟的严格SLO下，尽管GrandSLAm在较松的Kubernetes策略下表现更好，但在Parslo的优化下，部署成本依然减少了3.8倍。对于社交网络和媒体服务应用，混合校准的Parslo显著减少了部署成本，并在有限的迭代次数内确保了SLO目标不被违反，展示出其在复杂真实环境中的实用性。

最后，Parslo与基于机器学习的微服务扩展框架FIRM进行了比较。结果显示，尽管Parslo在成本优化上优于FIRM，但其响应速度相对较慢。在流量突增的情况下，FIRM能够更快地收敛到最终配置，而Parslo由于初始优化较慢，导致在服务扩展到足够容量之前队列积压现象更为严重。然而，Parslo与集中式机器学习系统可以协同工作，Parslo在稳态下最小化总成本，而集中式系统则适合快速应对瞬态流量变化，二者结合可以实现成本和响应速度的最佳平衡。

